# Crypto Pipeline Project

가상화폐 거래소에서 실시간으로 제공되는 데이터를 실시간으로 처리해 보자


## 개요

 **UPBit**, **Binance** 등 가상화폐 거래소 에서는 실시간 거래 데이터(거래, 호가, 가격 등)을 Websocket으로 받아볼 수 있는 API를 제공해 준다.
이를 활용해서 실시간으로 데이터를 스트리밍 > 가공 > 적재하는 ETL 파이프라인을 만들어 보려고 한다.

1. ETL 파이프라인을 구축하여 실시간으로 데이터를 적재한다.
2. 바이낸스의 경우에는 24시간 마다 하루치의 데이터를 파일로 다운받을 수 있게 제공해준다.
3. 위 파일을 다운받아 내가 실시간으로 적재한 데이터와 비교하여 손실된 데이터가 있는지 확인해야 한다
	- (선택사항) 손실이 발생했다면 몇% 인지도 기록하면 좋을 듯 하다
4. 특정 사건 등으로 거래량이 급증할 때도 데이터의 손실이 있으면 안된다.
5. 원하는 가상화폐 들의 데이터를 전부 가져올 수 있어야 한다.
6. 테스트 코드를 작성해 본다

## 기술 스택
> **우선 WebSocket쪽과 데이터 전처리 총 2개의 application으로 나눠진다.**

## 공통
**Docker**: 개발환경 통합, 각각 Application을 container로 분리하여 관리, 배포할 때 편하다.

## Streaming
**Websocket**: Websocket으로 실시간으로 데이터를 받아 올 목적으로 사용한다.
**Kafka**: Websocket으로 받은 데이터를 Kafka Producer를 사용하여 preprocessing 앱으로 데이터를 스트리밍 한다

**Apache Kafka**: 실시간으로 데이터를 스트리밍 해야 하기 때문에 선택했다. 데이터 처리하는 App과 Streaming하는 App이 분리되어 있기에 Streaming > preprocessing 쪽으로 데이터 보내줄 목적으로 사용한다.

## preprocessing
**Apache Flink**: 여러가지 도구 중에 **Spark Streaming**이랑 **Apache Flink**랑 고민했었는데 이유는
> 	1.	실시간으로 거래 데이터를 손실없이 가져와아 햔다.
> 2. 지연시간을 최소한으로 해야한다
> 3. 트래픽이 급증할 때도 최대한 손실이 없어야 한다.

근데 **Spark Streaming** 같은 경우는 실시간 처리가 아닌 소규모로 일괄처리 하는 형태라서 데이터가 한 번에 많이 몰리면 각 배치의 크기가 커지며 지연시간이 발생한다.

반면에 **Apache Flink**는 이벤트 시간을 기반으로 처리한다. 그래서 데이터가 지연되어 도착해도 정확한 시간을 기준으로 처리할 수 있어서 데이터가 손실되는 문제를 잘 해결할 것 같아서 이다.
> 그리고 알아보니까 PyFlink 라이브러리에서 대부분의 처리를 Java엔진에서 수행한다.
> Py4J 라이브러리를 사용해서 Java 기반으로 되어있는 Flink 엔진을 호출하고 Flink의 JVM 환경에서 실행되기 때문에 Java와 큰 차이가 없다
> 아주 복잡한 사용자 정의 함수(UDF: User-Defined Function)를 사용하는 경우가 아니라면 Java와 성능차이가 거의 발생하지 않는다

